<h1 align="center">Hi ðŸ‘‹, I'm Nathan</h1>

<p align="center">
  <b>Computer Architecture Â· GPUs Â· Accelerators Â· Systems @ MIT</b>
</p>

<p align="center">
  Optimizing kernels, building accelerators, and designing systems that push hardware to its limits.
</p>

<p align="center">
  <a href="https://github.com/nnt-git13">
    <img src="https://img.shields.io/badge/-GitHub-181717?style=for-the-badge&logo=GitHub&logoColor=white" />
  </a>
  <a href="https://www.linkedin.com/in/nathan-t-">
    <img src="https://img.shields.io/badge/-LinkedIn-0077B5?style=for-the-badge&logo=LinkedIn&logoColor=white" />
  </a>
  <a href="mailto:your-email@example.com">
    <img src="https://img.shields.io/badge/-Email-D14836?style=for-the-badge&logo=Gmail&logoColor=white" />
  </a>
</p>

---

## ðŸ”§ Skills

**Languages:** C Â· C++ Â· Python Â· CUDA Â· JavaScript Â· TypeScript Â· Verilog Â· Assembly

**GPU / ML:** CUDA Â· Triton Â· PyTorch Â· TensorFlow

**Hardware:** Verilog / SystemVerilog Â· RISC-V Â· FPGA Â· PCB Design

**Systems:** Linux Â· Git Â· Compilers (MLIR/LLVM) Â· ROS2 Â· Docker

---

## ðŸ“Œ Pinned Projects

### <a href="https://github.com/nnt-git13/flashflow">âš¡ FlashFlow</a>

GPU-optimized Transformer inference runtime featuring fused CUDA kernels, auto-tuning, and low-latency compute paths.

### <a href="https://github.com/nnt-git13/riscv_quant.accel">ðŸ“ˆ riscv_quant.accel</a>

A RISC-V Vector CPU + Quant Finance Accelerator with custom ISA extensions, pipelined execution units, and simulation tooling.

---

## ðŸŽ“ Education & Experience

**MIT** - Electrical Engineering w/ Computing and Mathematics

- **Research:** Undergraduate Researcher @ MIT AeroAstro, MIT Siegel Family Quest for Intelligence
- **Teaching:** Teaching Assistant - Classical Mechanics @ MIT Physics Department

**Current Focus:**
- Reinforcement learning of swarm dynamics
- GPU kernel optimization with CUDA and Triton
- Compiler infrastructure (MLIR/LLVM)
- Autonomous robotics and sensor fusion

---

<p align="center">
  <i>Always building. Always profiling. Always optimizing.</i>
</p>
